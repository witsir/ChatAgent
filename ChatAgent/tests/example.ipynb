{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## chat_agent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from ChatAgent import ChatgptAgent, ConversationAgent\n",
    "chat_agent = ChatgptAgent()\n",
    "conversation = ConversationAgent(chat_agent.session)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 16:07:23,201 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"7a912333-13d2-466c-bf13-b55ddb2853c6\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "data": {
      "text/plain": "'当然！这是一个经典的笑话：\\n\\n有一天，小明去参加驾驶考试。考官问他：“小明，你在红灯时应该做什么？” \\n\\n小明思考片刻后回答：“嗯，我会按下收藏按钮。”\\n\\n考官一脸困惑地问：“收藏按钮？你说的是哪个按钮？”\\n\\n小明得意地回答：“是手机上的收藏按钮！每当我看到红灯亮起，我就会拿出手机，把这个美丽的瞬间收藏起来。”'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.ask_chat(\"说一个笑话\", conversation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 自定义LLM chat_agent_LLM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, List, Mapping, Optional\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "class ChatAgentLLM(LLM):\n",
    "    chat_agent: ChatgptAgent\n",
    "    conversation: ConversationAgent\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ChatAgent\"\n",
    "\n",
    "    def _call(\n",
    "            self,\n",
    "            prompt: str,\n",
    "            stop: Optional[List[str]] = None,\n",
    "            run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "            **kwargs: Any,\n",
    "    ) -> str:\n",
    "        return chat_agent.ask_chat(prompt, conversation)\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\"chat_agent\": self.chat_agent, \"conversation\": self.conversation}\n",
    "\n",
    "\n",
    "chat_agent_LLM = ChatAgentLLM(chat_agent=chat_agent, conversation=conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Langchain 包装的 OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "openai = OpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 测试 PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 16:08:02,828 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"f3fda041-ddaa-4c26-b8ac-3a90f4e26197\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import  PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "_input = prompt.format_prompt(query=joke_query)\n",
    "output = chat_agent_LLM(_input.to_string())\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DatetimeOutputParser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, DatetimeOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "output_parser = DatetimeOutputParser()\n",
    "template = \"\"\"Answer the users question:\n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 16:12:45,453 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"4e4fc82c-2d16-4ec8-ac40-ef347b296b80\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Bitcoin was founded on January 3, 2009. The corresponding datetime string is \"2009-01-03T00:00:00.000000Z\".'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_chat_agent_LLM = LLMChain(prompt=prompt, llm=chat_agent_LLM)\n",
    "chain_chat_agent_LLM.run(\"around when was bitcoin founded?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\n2008-01-03T18:15:05.000000Z'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_openai = LLMChain(prompt=prompt, llm=openai)\n",
    "chain_openai.run(\"around when was bitcoin founded?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## MyStructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "class MyStructuredOutputParser(StructuredOutputParser):\n",
    "    my_structured_format_instructions = \"\"\"输出必须是下面这种格式的 markdown code 片段格式，包括前面的 \"```json\" 和后面的 \"```\":\n",
    "\n",
    "```json\n",
    "{{\n",
    "{format}\n",
    "}}\n",
    "```\"\"\"\n",
    "\n",
    "    def _get_sub_string(self, schema: ResponseSchema) -> str:\n",
    "        line_template = '\\t\"{name}\": {type}  // {description}'\n",
    "        return line_template.format(\n",
    "            name=schema.name, description=schema.description, type=schema.type\n",
    "        )\n",
    "\n",
    "    def get_format_instructions(self) -> str:\n",
    "        schema_str = \"\\n\".join(\n",
    "            [self._get_sub_string(schema) for schema in self.response_schemas]\n",
    "        )\n",
    "        return self.my_structured_format_instructions.format(format=schema_str)\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"answer\", description=\"用户提问的回答\"),\n",
    "    ResponseSchema(name=\"source\", description=\"回答用户提问所引用的内容，前后4句话以上\")\n",
    "]\n",
    "my_structured_output_parser = MyStructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 16:26:30,790 - use_requests.py - 270 - ERROR - [Status Code] 403\n",
      "2023-06-28 16:26:30,798 - use_requests.py - 306 - WARNING - Requests403Error: Request 403，update cookies, call _get_a_conversation() again\n",
      "2023-06-28 16:27:03,818 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"b791d77f-e930-4485-99f8-c04150dfacd6\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'answer': '老胡想说，那些炒作“胡锡进商业版图”的人应该大致了解老胡退休后的实际情形，也能搞明白那些环时下属或者参股公司至多是“环球时报商业版图”，而非“胡锡进商业版图”。但他们仍然搞这种有悖真实情况的炒作，我认为至少其中有一些人是心术不正的。',\n 'source': '一些人因老胡进入股市而编造、炒作“胡锡进商业版图”，真是无聊至极。众所周知，老胡曾长期担任环球时报社总编辑、法人代表，但我2021年底退休，自然要同时退出在环球时报社和子公司的所有领导职务，与报社切断利益关系。报社虽聘我为“环球时报特约评论员”，但我也主动放弃了在各大平台对该称呼的使用，能改的都改了，避免一旦我说话不慎牵连环球时报。环球时报社未能及时对我担任职务的环时下属公司及参股公司做商业注册变更，应该是有流程上的技术原因。环时的同志今天上午对我说，他们会加速办理那些公司的商业注册变更。顺便说一句，老胡之前作为环时负责人在那些公司兼职期间，没有从那些公司获得一分钱的收入。'}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "format_instructions = my_structured_output_parser.get_format_instructions()\n",
    "with open('downloadfiles/text_1.txt') as f:\n",
    "    doc = f.read()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"根据'[[[ ]]]'包裹内容回答用户问题.\\n[[[{context}]]]\\n{format_instructions}\\n{question}\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions, \"context\": doc}\n",
    ")\n",
    "_input = prompt.format_prompt(question=\"文中老胡是如何反驳炒作“胡锡进商业版图”？\")\n",
    "output = chat_agent_LLM(_input.to_string())\n",
    "my_structured_output_parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Retry parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.output_parsers import (\n",
    "    PydanticOutputParser,\n",
    "    OutputFixingParser,\n",
    "    RetryOutputParser,\n",
    "    RetryWithErrorOutputParser\n",
    ")\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Based on the user question, provide an Action and Action Input for what step should be taken.\n",
    "{format_instructions}\n",
    "Question: {query}\n",
    "Response:\"\"\"\n",
    "class Action(BaseModel):\n",
    "    action: str = Field(description=\"action to take\")\n",
    "    action_input: str = Field(description=\"input to the action\")\n",
    "parser = PydanticOutputParser(pydantic_object=Action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 16:39:05,889 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"6bcb1093-be4a-4b71-8ab0-036aeb6dff8b\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Action(action='search', action_input='')"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_response = '{\"action\": \"search\"}'\n",
    "prompt_value = prompt.format_prompt(query=\"who is leo di caprios gf?\")\n",
    "fix_parser = OutputFixingParser.from_llm(parser=parser, llm=chat_agent_LLM)\n",
    "fix_parser.parse(bad_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 16:38:57,947 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"1cbd52a5-d47c-4565-8218-51df73153ecc\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Action(action='search', action_input='who is leo di caprios gf?')"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retry_parser = RetryWithErrorOutputParser.from_llm(\n",
    "    parser=parser, llm=chat_agent_LLM)\n",
    "\n",
    "retry_parser.parse_with_prompt(bad_response, prompt_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Auto-fixing parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Actor(BaseModel):\n",
    "    name: str = Field(description=\"name of an actor\")\n",
    "    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n",
    "\n",
    "actor_query = \"Generate the filmography for a random actor.\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "misformatted = \"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Failed to parse Actor from completion {'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}. Got: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m/Volumes/Usir/langchain/langchain/output_parsers/pydantic.py:25\u001B[0m, in \u001B[0;36mPydanticOutputParser.parse\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m     24\u001B[0m     json_str \u001B[38;5;241m=\u001B[39m match\u001B[38;5;241m.\u001B[39mgroup()\n\u001B[0;32m---> 25\u001B[0m json_object \u001B[38;5;241m=\u001B[39m \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpydantic_object\u001B[38;5;241m.\u001B[39mparse_obj(json_object)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/json/__init__.py:359\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    358\u001B[0m     kw[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparse_constant\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m parse_constant\n\u001B[0;32m--> 359\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/json/decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03mcontaining a JSON document).\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 337\u001B[0m obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/json/decoder.py:353\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[0;34m(self, s, idx)\u001B[0m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 353\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscan_once\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mOutputParserException\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmisformatted\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Volumes/Usir/langchain/langchain/output_parsers/pydantic.py:31\u001B[0m, in \u001B[0;36mPydanticOutputParser.parse\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m     29\u001B[0m name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpydantic_object\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[1;32m     30\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to parse \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m from completion \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Got: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 31\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m OutputParserException(msg)\n",
      "\u001B[0;31mOutputParserException\u001B[0m: Failed to parse Actor from completion {'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}. Got: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "parser.parse(misformatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "new_parser = OutputFixingParser.from_llm(parser=parser, llm=chat_agent_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 16:50:04,446 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"4db1632d-0daa-4e14-932c-567737635278\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Actor(name='Tom Hanks', film_names=['Forrest Gump'])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_parser.parse(misformatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Summarization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('downloadfiles/text_2.txt') as f:\n",
    "    some_text = f.read()\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=2300,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "texts = text_splitter.create_documents([some_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 17:00:42,176 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"a0afd1d1-44d8-4c25-a39c-6a493b32663c\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 17:00:54,674 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"f1968d4d-7c89-4080-8399-41fbcc0fdbd0\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 17:01:24,982 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"891e5cda-386b-42a7-a822-b73cf5ab6e36\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 17:01:45,588 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"1c9a84c5-7060-4c38-a69b-96fc082e900f\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "2023-06-28 17:02:01,161 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"3f7168bf-c6a9-4e49-9010-f278973fb0a2\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input_documents': [Document(page_content='上海仍是上海吗？解封一年后，滴水不漏式文化与身心管治\\n今日大上海，若要引进外国演出而能确保通过审查，最方便是找些没有歌词的DJ 派对，和只是弹奏的爵士乐。\\n\\n特约撰稿人 文強 發自上海 2023-06-20\\n2023年5月30日，翻修后的上海电影艺术中心。摄：VCG/VCG via Getty Images\\n      \\n文强，作家，时尚传媒人，自香港到上海，超过十年沪漂。\\n\\n文化市场综合行政执法队，简称“文管”，它不是全新工种，但高调出现在上海。试想像：在各种文化及演出场合，总有专门人员穿著制服坐在席间，在场震摄，默默留意台上一字一句，又或者关心身边观众有没越轨。\\n\\n解封一年后，上海是否仍是那个上海？\\n\\n六月是上海国际电影节惯常举行的季节。今年许多选片回复到一票难求的热闹，映后交流时，观众席仍然满载渴望提问与表达的眼神。\\n\\n一年前并非这样，当时上海才刚从封城两个月的噩梦中醒来，人们惊魂未定，电影节宣布延期。现在，观众重返戏院了，今年电影节其中一部最惹来关注的作品，是在此作首映、上海人罗冬执导的《梅的白天与黑夜》，追踪一位年越70岁叫陈玉梅的上海老阿姨的日常生活与约会故事。\\n\\n影片近乎没差评，大家都为梅姨的生命力、直率与典型的上海式世故而着迷。阿姨太喜爱镜头了，以至本应是记录片，却看得像剧情片。有介绍提及，这是一部主要拍摄在“怡情前”的片子，故此也不奇怪，片中人都没戴口罩。有留言尝试纠正，说该是“疫情”，不是“怡情”。版主回复：“不用更正，我们故意的，那个正确的词已无法正确使用了，望周知。”\\n\\n从而又记起五月份笔者曾到过上海的医院，医护提到，虽然坊间不断有二次阳的病人，可是医院方已不会再视之为新型冠状病毒的案子来登记了。更甚的说法是：已经没有这一项了，所有同类的症状，皆不会再被界定为新型冠状病毒。从字面和数据意义上，疫情，新冠，在这里都没有了。\\n\\n难以想像，已经过了一年。后来和不少朋友的闲聊中，都会提到一个说法：对于一些经历，譬如上次见的某人，去过的某地，一般都起码是三年前的事了，而大家都总不觉得有那么久。\\n\\n人生中有三年像空白了。这三年去哪了？\\n\\n“那个正确的词已无法正确使用了，望周知。”\\n\\n《梅的白天与黑夜》的电影内容是追踪一位年越70岁叫陈玉梅的上海老阿姨的日常生活与约会故事。\\n\\n末日后走出来的人\\n有点老记忆的上海人，戏称去年这时候，是另一次上海的解放——意思是类比1949年5月27日解放军进城接管上海。像那些末日后重新从地底藏所走出来的人一样，大家只想再次在日光地上，望著天，看看地球有什么改变没有，然后庆幸彼此仍能呼吸。\\n\\n而好快就发现，那其实更像是丧尸电影，人与人之间虽说庆幸重遇，但不免心底有种保留，担心对方会否是没被察觉的带毒之躯。当政府机关重新运作，坊间说民政部门第一个热门的申办需求，不是移民（领馆还未开启，政府也不鼓励人往外跑，因而有很长一段时间许多人的护照均过期），而是离婚。那个被广传的笑话可能有些道理：再这样关下去，我跟老公可能真要培养出感情了！\\n\\n真正听到的最多朋友异动个案，则是在上海外国人的离开。也是去年相若时间，一个抽样调查数据相当引起讨论，就是对在上海工作的外国人发抽样问卷，结果是当中有48%的人会选择一年内离开上海，当中最显要的比重，是教育相关职业人。\\n\\n这次巨型的外国人逃离潮，于一位外国朋友从领馆得到的数据中得到证实，相比起疫情前，他的国家（也算占在上海外侨主要比重）的在沪人口，下跌了八成。再经房产公司的指标从旁证实，说外国人租房市场大跌，一幅外国心落荒逃离上海的场面，被广泛接受作为一年前的上海解封即景。\\n\\n2023年5月6日，中国上海举行的第三届外滩艺术节期间，一名骑自行车的人骑车经过墙上的猫像涂鸦。摄： VCG/VCG via Getty Images\\n\\n上海式沉默\\n\\n是否刻意的遗忘？向前看仍是一种无奈的主流价值。和很多不被鼓励去讨论的事一样，民众似乎有种落力配合这叙事的惯性。抱怨、不忘、反省，更不要说追究，被视为不够正能量与太不务实。\\n\\n一年过去，上海复常了吗？\\n\\n街上行人目测八成都不戴口罩了。政府机关和网约车司机还有较严格规定，所以仍是口罩随脸。也不用再亮什么健康码。曾经每个街角都设置的核酸亭，大部份没留下半点痕迹，除了一些地上的印记，或没有被撕掉的写着“保留2米距离”的黄贴纸。\\n\\n处处都以核酸亭的“不在”来提醒它曾经的在场：不是一度每天都在这路口这转弯排队做核酸吗？怎么突然就没有了。只有在某些像医院的后院，当一个被癈置的核酸亭忘记回收仍搁在那里，那双从检测口中伸出的手套仍像鬼手一样摊在那儿之时，才令人有一秒的不协调：都忘得这么快了？\\n\\n是否刻意的遗忘？无论如何，重新开放，回复过往，向前看仍是一种无奈的主流价值。在这儿，和很多不被鼓励去讨论的事一样，民众似乎有种落力配合这叙事的惯性。抱怨、不忘、反省，更不要说追究，被视为不够正能量与太不务实。\\n\\n令情况更极端的是，当一切记忆都只存于网络，就注定那记忆的不牢固，它随时被抽空、删除、导引、改写。尤如现在再搜去年此刻的关键词，如封城、方舱、消杀、四月之声，已经很难可以从中拼合出其时的记忆。', metadata={}),\n  Document(page_content='令情况更极端的是，当一切记忆都只存于网络，就注定那记忆的不牢固，它随时被抽空、删除、导引、改写。尤如现在再搜去年此刻的关键词，如封城、方舱、消杀、四月之声，已经很难可以从中拼合出其时的记忆。\\n\\n有关“封城”，跳出来最多的是去年三月份官方的辟谣说上海不会封城。“方舱”最令人失笑，有一条的标题是：进去了就不想出来。打动亿万人也终令非上海居住人知悉封城状况的“四月之声”作为历史文献，难以找到其声画版本。\\n\\n好久以前读《繁花》，小说中一个出现频率最高，也最常用以表现上海人那通常不想言喻的做派的一个词：“不响”，从来未确切读懂它的意义。角色遇到好些情节，不置可否，金宇澄就写“沪生不响”、“阿宝不响”，既一言终结又意味深长。\\n\\n金宇澄曾解释到：其实“不响”是上海话中最常用词之一，表面上意思就是不语、无语、沉默、不说话，但内涵就很复杂。可能是不愿意表态，也可能不同意，还可能是很反感，或者是根本就麻木没意见。上海人不习惯进一步说明，很多时候都要靠自己体会。\\n\\n现在才知，大概那就是此情此景。上海，不响。\\n\\n当一切记忆都只存于网络，就注定记忆的不牢固，随时被抽空、删除、导引、改写。尤如现在再搜去年此刻的关键词，如封城、方舱、消杀、四月之声，已很难从中拼合出其时的记忆。\\n\\n2023年5月22日，中国上海，戴著头盔的工人站在展示奢侈品牌广告的建筑物外。摄：Hugo Hu/Getty Images\\n\\n排队进名店，还是消费大降级？\\n\\n然而遭历劫难的城市，又怎可能把伤口遮掩得绝无破绽。在著名高级大型商场内，排队进名店的人龙仿佛表达出一个回到过往美好时光的表象，而这些国际名牌实际上去年全年至今年第一季的中国销售，都以双位数字增长支持了这说法。\\n\\n但高端市场消费和普罗群众还是有不小距离，餐饮业界则表达了另一幅图像：消费的降级，今年再去往日高档餐厅林立的外滩，就发现不少过往的名店已关。可以说，两极化更鲜明，要么就是几万、几十万的国际名牌消费；另一极端就是几十元、上百元的低价市场。在电商带货普及的这三年，实体店生意受最大打击之余，造就了更全面的线上交易习惯。\\n\\n于是，还走于路上的人有了新任务。被夸大称为宇宙中心的上海安福路武康路交界口，它另一端是乌鲁木齐路，一章现在被埋没了的抗争片段曾在这儿上演，好大程度上加速推进了解封和防疫政策的转向。如今，这条路是自媒体、网红与街拍者的天堂。每天有上几十位貌似摄影师的大叔或哥哥，拿著长短镜头，捕捉每个穿搭得宜的可能目标物。\\n\\n回到家庭情景，中产的消费心态转变特别明显，这种心态反映于对一切非必要开支的审慎。对他们而言，只有健康、教育、饮食开支是必要的。就难怪其中一个重灾区的健身馆经理不断抱怨，现在都没有了预付年卡的市场。\\n\\n广义中产朋友家庭的一大话题，肯定是子女升学。身边起码有五位朋友的孩子在过去一年之内到外国读书，小学到中学都有。他们选择学校也有了新的看法，东南亚成为一个不断被提起的目的地，部分原因是孩子的母亲要亲身过去陪读，而那里的学费往往是在中国的有名国际学校或西方国家学校的三分一。在平衡了成本及学位接轨度之后，东南亚的国际学校被认为是新发现的可行选择。\\n\\n引入外国演出技术上难关层层，例如歌单歌词得通过专门认可翻译单位翻译后后送审（不相信民间申报者自行翻译）。搞手为免麻烦，引进外国演出时会找没有歌词的演出如DJ 派对，和只弹奏的爵士乐。\\n\\n2023年5月27日，一个打扮成薯条吉祥物的人站在中国上海街头。摄：Aly Song/Reuters/达志影像\\n\\n国际化在转变？\\n\\n如果要说这一年来，众多疫后社会新常态有哪些值得加以深入了解，该就是文化活动市场的被驯服，以及上海的外国人逃离现象。不久前，一条火爆视频把一个大家都愿意相信的预想变得合理，那是上千万点击的视频，其带有骇人效果的结论是：过往充满洋化气息的上海复兴路，如今找不到一个洋人了。\\n\\n这说法当然是以极端化去蹭流量，实际情况以笔者感受，则是外国人在上海的数字下降，已是一个持续多年的现象，只是去年超乎常理的疫情管控，变成很多外国人决定离开上海的最后一根稻草。\\n\\n好大程度上，是疫情加急了上海这次外国人的洗牌，而背景则是近些年中国在不同领域尝试本土化过程，从管理阶层、意识形态到文化商品，尽量希望由自己人接手；而这与更上层领导人总体的“伟大复兴”或“中国梦”政策或有因果关系。\\n\\n上海正面对这转型，由过往国际化演变成中国本土中产化。\\n\\n职场上出现的现象，是外国在华企业的高管大移位。过往二十年，国际大公司大量外派高管到中国，上海正是其落地首选。而随著管理层的本地化，那批高薪待遇外国人及家庭相继离开，引致连锁的家庭、就学、居住、消费市场的转型。\\n\\n但有多位房地产中介令笔者得知，上海房产市场其实并没有大幅下跌，主因是虽有外国家庭退场，但上海作为中国最进步及繁荣大都会，仍有大量外省人来到上海发展。当然他们对房屋及生活消费的需求，肯定跟外国人有所不同。上海正面对这转型，由过往国际化演变成中国本土中产化。\\n\\n2023年6月2日，一名乘客乘坐渡轮穿越中国上海的黄浦江。摄：Raul Ariano/Bloomberg via Getty Images\\n\\n那句歌词只在上海唱不出来？', metadata={}),\n  Document(page_content='2023年6月2日，一名乘客乘坐渡轮穿越中国上海的黄浦江。摄：Raul Ariano/Bloomberg via Getty Images\\n\\n那句歌词只在上海唱不出来？\\n\\n由话剧、脱口秀到乐队演唱，一套新的监管系统正在应用。一线城市上海、北京申报演出时更形严格，而其他主拼经济的二三线城市如天津、苏州，反而吸纳了京、沪溢出的观众。\\n\\n在演出市场上，有两种现场表现方式相当叫座，一种是传统的歌手演唱会或DJ派对，都是得益于长期的半封闭后，对演出饿得太久，由主办方到观众都进行了“报复式”的参与。上海实在也是从音乐会、话剧、派对到脱口秀都演出密度最高的城市。\\n\\n以上海的演唱会为例，今年五月开始，已举行或确认了下半年档期的音乐会就起码有梁静茹、刘若英、张信哲、万能青年旅店、周杰伦、陈奕迅。另一类则是曾一度疯魔上海北京、最近才被打压的脱口秀。\\n\\n在脱口秀还大有市场之时，可看到不少一度被弃用全无人气的商场，都被改装成小型脱口秀演出场所。去看新冒起的脱口秀表现者，吐糟一下生活的光怪陆离（当然避开政治玩笑），曾一度成为一种白领职场工余娱乐新潮流。\\n\\n也正是House事件提醒大家去更关注那个对演出更严苛监管的新常态，那同时是导致各种较小型独立演出面临更多审批难度的文化现状。可以说，由话剧、脱口秀到乐队演唱，一套新的监管系统正在应用。\\n\\n若是中国本地乐团演出，除歌词要提前送审，现场还会有专人监控演出版本是否跟事前过检的是百分百相同，不容许任何即场改变。\\n\\n一位资深的独立音乐会搞手说出了现行规管的具体严格措施。他说这阵子，上海北京在申报演出时更形严格，其他主力拼经济的二、三线城市像天津、苏州，反而吸纳了北京和上海溢出来的观众。\\n\\n若是中国本地乐团演出，除歌词要提前送审（这个也是过往传统需要，可是以前相对有弹性，现在则会指明歌词能否过关及要如何删减），现场还会有专人监控演出版本是否跟事前过检的是百分百相同，不容许任何即场改变。\\n\\n正是在这更严格的规管下，才得以解释万能青年旅店最近在上海演出他们最知名歌曲《杀死那个石家庄人》时，得以纯音乐版本去奏出的现象。这个现在被乐迷形容为“这沉默震耳欲聋”的钢琴与色士风（萨克斯风）版本，董亚千并没有如常声嘶地开口，只有上万位观众在默默背诵着“如此生活30年 直到大厦崩塌”，那些早刻铭于心的歌词。\\n\\n是乐队的新编曲安排？但回顾万青最近于其他城市的演出，都仍是唱着带歌词的版本。难怪不无幽默的网友，总结出这就是“文明上海版”的《杀石》。\\n\\n\\n2023年5月26日，中国上海sony博览会上，市民在电影拍摄体验区。摄：Costfoto/NurPhoto via Getty Images\\n滴水不漏式文化与身心管治\\n\\n这阵子上海也以“文管”部门将统一穿辨认度高的制服来隆重推出，达到一种可以说是在场震慑的作用。可说是继城管、农管后，滴水不漏式文化与身心管治的体现。\\n\\n另一方面，要引入外国演出不是没可能，但技术上各种难关会层层卡住，例如外国演出艺人未必拿到中国签证，若是带歌词的演出，歌单歌词也得通过专门认可翻译单位翻了后送审（不相信民间申报者自行翻译）。搞手最后表示，为免麻烦，现在引进外国演出最大机会的，就是都找些没有歌词的演出，例如DJ 派对和只弹奏的爵士乐。\\n\\n那是演出前的审查，还有新兴的演出过程中的监控。这也就涉及另一样文化监管的执行岗位：文化市场综合行政执法队，简称“文管”。文管不是全新的工种，但高调出现在上海，确是对向来说自己尤如国际大都会的上海有点讽刺。\\n\\n试想像一下，在各种文化及演出场合（事实上它的范围极广，包含了一应广义上的文化旅游娱乐演出场所，监管领域包括防疫执行、消防、卫生、演出内容、观众行为等等），总有专门人员坐在席间，默默留意著台上的一字一句，又或者关心身边观众有没越轨。\\n\\n她打开手机小电筒对照笔记本中圈好，认为较易出事的重点段落或句子，一句句确认演出并没加添或修改什么。她在这过程中，提升了自己的文化修养，又为文化质量的监管作出了贡献。\\n\\n这岗位全国皆有，不同的是，这阵子连上海也以这部门将统一穿辨认度高的制服来隆重推出，达到一种可以说是在场震慑的作用。可说是继城管、农管后，滴水不漏式文化与身心管治的体现。此前，一位曾当“文化市场内容巡查志愿者”的上海姑娘记述了她当“文化执法”时的心得，尽显此政策之正能量。\\n\\n从2020年9月开始，她每月要看两三部剧，并写下报告。为当好这份义工，她事前收到将去作目标监测的话剧的剧本，先细心记住每个段落，到演出坐于台下，她打开手机小电筒对照笔记本中圈好，认为较易出事的重点段落或句子，一句句确认演出并没加添或修改什么。她在这过程中，提升了自己的文化修养，又为文化质量的监管作出了贡献。\\n\\n同一个电影节，更多的镁光与报导，是关于如博纳这种大电影公司预告将推出近二十部大作，提醒大家这才是电影与娱乐文化的未来。', metadata={}),\n  Document(page_content='同一个电影节，更多的镁光与报导，是关于如博纳这种大电影公司预告将推出近二十部大作，提醒大家这才是电影与娱乐文化的未来。\\n\\n当《梅的白天与黑夜》在戏院中放映，是否一样有这些志愿者或新的制服人员在稽查？这部全上海话、只聚焦一个小市民寻常生活的小故事，气势可能不够宏大，没有对大叙事有多大影响。同一个电影节，更多的镁光与报导，是关于如博纳这种大电影公司，最后有请周润发一众上台造势，预告将推出近二十部大作，当中有林超贤的《红海行动2:虎鲸行动》、庄文强的《枭雄》、徐克的《智取威虎山前传》和刘伟强监制《汶川大地震》及执导《上甘岭》，提醒大家这才是电影与娱乐文化的未来。\\n\\n毛尖说《梅的白天与黑夜》：“从此，上海有了全新的女主，健康，彪悍，浪漫，粗野。”好奇梅姨经历了去年的封禁，这态度可有任何转变？一度再不能每天跨过闹市，到相亲角或宜家跟各式爷叔约会。抑或，上海始终仍会是那个上海。今天，她又已经如常的奔跑在赴约的路上。', metadata={})],\n 'intermediate_steps': ['2023年6月的上海，解封一年后，人们重返日常生活。上海国际电影节恢复热闹，观众充满期待。电影《梅的白天与黑夜》受到关注，讲述了一位70岁上海老阿姨的故事。然而，尽管解封已过一年，人们仍心存保留，担心他人可能是潜在的感染者。外国人在上海的离开也引起了讨论，教育相关职业人士的离开比例较高。然而，上海的街头已经恢复常态，口罩使用率下降，核酸亭也逐渐消失。人们似乎选择遗忘过去，主流价值是向前看。记忆在网络中不稳定，随时可能被删除或改写。',\n  '这段文章讨论了上海在疫情后的变化和转型。作者指出，当所有记忆都只存在于网络时，记忆变得不牢固，容易被删除、篡改或丧失。他描述了通过搜索关键词如“封城”、“方舱”、“消杀”和“四月之声”来回顾去年的记忆变得困难。文章还提到了上海的消费市场的两极分化，高端市场的消费增长，但餐饮业则出现降级消费的趋势。此外，文章还讨论了中产阶级的消费心态变化，以及外国人在上海的减少和本土化转型的影响。文章最后提到了上海房地产市场的变化，虽然外国家庭离开了，但仍有大量外省人来到上海发展，推动了城市的本土中产化。',\n  '2023年6月2日的文章讨论了中国文化演出市场的监管和变化。在一线城市如上海和北京，演出审查要求更为严格，而二三线城市如天津和苏州则成为了吸纳溢出观众的地方。演出市场上，传统的歌手演唱会和DJ派对表现良好，而脱口秀也一度风靡，引发了一些商场改装成小型脱口秀场所的现象。新的监管系统要求本地乐团演出歌词提前送审，并在现场监控演出版本是否与事前审核的版本完全一致。这导致了一些独立演出面临更多审批难度。外国演出的引入也面临各种技术难题和审查要求，因此引进没有歌词的演出成为主要选择。此外，文章还提到了上海推出的文化市场综合行政执法队（文管），他们在演出场合默默监管演出内容和观众行为。文章最后提到了博纳等大型电影公司的预告，强调了电影和娱乐文化的未来。',\n  '文章提到了电影与娱乐文化的未来展望。在同一个电影节上，更多关注的是大电影公司如博纳宣布将推出近二十部大作，强调这才是电影与娱乐文化的未来。与此同时，文章也提到了一部名为《梅的白天与黑夜》的电影，该片聚焦一个小市民的普通生活，可能没有对大叙事产生太大的影响。然后，文章回顾了去年该片被封禁后的情况，以及梅姨（可能是指电影中的角色）的态度是否有所改变。最后，文章以上海作为结尾，提到梅姨已经恢复正常，并继续在上海奔跑。'],\n 'output_text': '这段文章讨论了2023年6月的上海的现状和转变。文章提到解封一年后，上海国际电影节恢复热闹，观众期待着电影《梅的白天与黑夜》的放映，该片讲述了一位70岁上海老阿姨的故事。然而，尽管解封已过一年，人们仍然对他人可能是潜在的感染者保持警惕。外国人离开上海引起了一些讨论，教育相关职业人士的离开比例较高。尽管如此，上海的街头已经恢复正常，口罩使用率下降，核酸检测亭也逐渐消失。人们似乎选择遗忘过去，主流价值是向前看。文章还提到了网络记忆的不稳定性和容易被删除或改写的问题。'}"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "prompt_template = \"\"\"对下文进行一个简短的总结:\n",
    "\n",
    "\n",
    "{text}\n",
    "\n",
    "\n",
    "总结:\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "chain = load_summarize_chain(chat_agent_LLM, chain_type=\"map_reduce\", return_intermediate_steps=True, map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "\n",
    "chain({\"input_documents\": texts})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## AnalyzeDocumentChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### load_qa_chain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "with open(\"downloadfiles/text_4.txt\") as f:\n",
    "    text  = f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 17:44:02,758 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"45b727d0-c649-402d-a917-cce1d67f08db\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 17:44:15,261 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"fb37e1f8-9d7e-49a9-8527-d806fa2c74ea\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 17:44:22,623 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"0a72af9b-9317-47f6-98c4-1079ebcd1101\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1995 > 1024). Running this sequence through the model will result in indexing errors\n",
      "2023-06-28 17:44:43,098 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"f9ce8467-75ba-4396-85d3-d2ba176b0537\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Chinese urge caution for several reasons:\\n\\n1. The potential war with Taiwan could mean taking on a nuclear-armed superpower (referring to the United States), which poses significant risks and uncertainties.\\n\\n2. Chinese officials pay close attention to online opinion, and they are aware that there are influential netizens who oppose the idea of going to war. Even among ardent nationalists, there are fissures, and some urge caution or argue that military action may not be necessary.\\n\\n3. The setbacks faced by Russia during its invasion of Ukraine and the West's solidarity in response to it may have sobered some supporters of rapid steps towards reunification by force. The Chinese leadership may be cautious due to the unpredictability of the outcome and potential consequences.\\n\\n4. The supply of arms by the United States to Taiwan and its military buildup in the region are seen as challenges by some Chinese nationalists. To counter this, there are suggestions to strengthen China's air, rocket, and naval forces, indicating that there are concerns about China's military capabilities.\\n\\n5. Public opinion and criticism play a role in shaping the approach. Some radical nationalists have faced fierce criticism online, even from within the nationalist camp and more liberal factions.\\n\\n6. There are netizens who express misgivings about going to war, citing their marginalized position in peacetime and questioning why they should bear the burden of conflict. Such sentiments, including the notion that children of leading cadres should go first, are being considered by officials.\\n\\nOverall, the combination of geopolitical risks, potential domestic opposition, and a cautious assessment of the military and political landscape contribute to the Chinese urge for caution.\""
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "qa_chain = load_qa_chain(chat_agent_LLM, chain_type=\"map_reduce\")\n",
    "qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain)\n",
    "qa_document_chain.run(input_document=text, question=\"Why Chinese urge caution?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### load_summarize_chain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 17:43:13,703 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"3637556a-49e3-413e-b0c4-3be69fa4eb90\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 17:43:25,479 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"41c46021-4145-4f1c-a420-c7836bb13c79\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 17:43:32,836 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"36fc9adf-1d63-4d20-8c5f-046f237f3a0b\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 17:43:43,485 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"6b5be2d5-f6ce-4db6-87e5-88b632128ed6\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Chinese nationalists show caution and divisions regarding a potential war with Taiwan, with some urging restraint and questioning the necessity of war. President Xi Jinping and Chinese officials may prefer caution due to risks and uncertainties, including confronting a nuclear-armed superpower and public support concerns. Recent surveys indicate relatively low support for immediate military action among the Chinese population. Russia's setbacks in Ukraine and Western response may have tempered support for rapid military action. Proposals to address challenges and conditions for war suggest significant obstacles and a need for more time. Radical nationalists advocating extreme measures have faced criticism. Some netizens express reservations about participating in a war, highlighting feelings of neglect and suggesting government officials' children should go first. Chinese officials may consider such sentiments.\""
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "summary_chain = load_summarize_chain(chat_agent_LLM, chain_type=\"map_reduce\")\n",
    "summarize_document_chain = AnalyzeDocumentChain(combine_docs_chain=summary_chain)\n",
    "summarize_document_chain.run(input_document=text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## load_qa_chain 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=2200,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "with open(\"downloadfiles/text_3.txt\") as f:\n",
    "    text = f.read()\n",
    "texts = text_splitter.create_documents([text])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 18:20:55,225 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"ca9dfc91-0f8f-46a1-bfd0-2c5b501a56f8\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 18:20:58,880 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"797e2edf-b868-4c08-9ac6-8ba4293aca3e\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 18:21:09,295 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"f0ff8de7-c44d-4ea1-a8f8-6ae2dae6ca22\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'intermediate_steps': ['“16MW机组吊装施工规程中面临“施工环境恶劣，海况复杂，施工安全风险高”、“风机容量大，施工难度大，设备选型难”、“大型吊装任务多，安全管控压力大”这三大难点。”',\n  '\"正因此该船建造难度远超普通船舶。\"'],\n 'output_text': '16MW海上风电机组建造的最大难点包括施工环境恶劣、海况复杂、施工安全风险高，风机容量大、施工难度大、设备选型难以及大型吊装任务多、安全管控压力大等。这些因素导致该机组的建造难度远超过普通船舶。'}"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "question_prompt_template = \"\"\"使用长文档中的以下部分，查看是否有任何文本与回答问题相关。仅返回任何相关的原样原格式文本。你不要自己添加内容。\n",
    "\n",
    "[[[{context}]]]\n",
    "\n",
    "问题: {question}\n",
    "原样文本：\"\"\"\n",
    "QUESTION_PROMPT = PromptTemplate(\n",
    "    template=question_prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "combine_prompt_template = \"\"\"利用下面的相关段落文本回答用户的问题，\n",
    "如果你不知道答案就回复：无法解答。不要编造内容回复。\n",
    "\n",
    "问题: {question}\n",
    "\n",
    "[[[{summaries}]]]\n",
    "\n",
    "答案:\"\"\"\n",
    "COMBINE_PROMPT = PromptTemplate(\n",
    "    template=combine_prompt_template, input_variables=[\"summaries\", \"question\"]\n",
    ")\n",
    "\n",
    "load_qa_chain_map_reduce = load_qa_chain(chat_agent_LLM, chain_type=\"map_reduce\", return_map_steps=True, question_prompt=QUESTION_PROMPT, combine_prompt=COMBINE_PROMPT)\n",
    "query = \"文中海上风电机组建造的最大难点是什么？\"\n",
    "load_qa_chain_map_reduce({\"input_documents\": texts, \"question\": query}, return_only_outputs=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 翻译"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('downloadfiles/text_5.txt') as f:\n",
    "    text = f.read()\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1600,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    ")\n",
    "texts = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "json_format=\"\"\"[\n",
    "  {\n",
    "    \"English\": \"Hello, how are you doing today?\",\n",
    "    \"Chinese\": \"你好，你今天好吗？\"\n",
    "  },\n",
    "  {\n",
    "    \"English\": \"Thank you so much for your help!\",\n",
    "    \"Chinese\": \"非常感谢你的帮助！\"\n",
    "  },\n",
    "  {\n",
    "    \"English\": \"I'm sorry for the mistake I made.\",\n",
    "    \"Chinese\": \"对于我犯的错误，我感到很抱歉。\"\n",
    "  }\n",
    "]\"\"\"\n",
    "translate_prompt_template = \"\"\"You are a translation engine;\n",
    "Your first step should be to separate the text into paragraphs, then translate each paragraph into Chinese, response in the json output. Remember to escape characters when necessary.\n",
    "\n",
    "examples:\n",
    "```json\n",
    "{json_format}\n",
    "```\n",
    "\n",
    "{context}\n",
    "\n",
    "json output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(template=translate_prompt_template,input_variables=[\"context\",\"json_format\"])\n",
    "partial_prompt = prompt.partial(json_format=json_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "translate_chain = LLMChain(llm=chat_agent_LLM,\n",
    "                           prompt=partial_prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 20:56:34,139 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"8dbabdd3-fb14-4fc9-8273-2ddb51434825\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"English\": \"Talking about AI in human terms is natural—but wrong\",\n",
      "    \"Chinese\": \"以人类的方式谈论人工智能是自然的，但是是错误的\"\n",
      "  },\n",
      "  {\n",
      "    \"English\": \"When it comes to artificial intelligence, metaphors are often misleading\",\n",
      "    \"Chinese\": \"谈到人工智能时，隐喻常常是具有误导性的\"\n",
      "  },\n",
      "  {\n",
      "    \"English\": \"A ghost coming out of a computer screen\",\n",
      "    \"Chinese\": \"一个从计算机屏幕中走出来的幽灵\"\n",
      "  },\n",
      "  {\n",
      "    \"English\": \"Jun 22nd 2023\",\n",
      "    \"Chinese\": \"2023年6月22日\"\n",
      "  },\n",
      "  {\n",
      "    \"English\": \"My love’s like a red, red rose. It is the east, and Juliet is the sun. Life is a highway, I wanna ride it all night long. Metaphor is a powerful and wonderful tool. Explaining one thing in terms of another can be both illuminating and pleasurable, if the metaphor is apt.\",\n",
      "    \"Chinese\": \"我的爱情如同一朵红色的玫瑰。它是东方，朱丽叶是太阳。生活是一条公路，我想整夜驾驶。隐喻是一种强大而美妙的工具。如果隐喻恰当，用一种事物解释另一种事物可以既有启发性又令人愉悦。\"\n",
      "  },\n",
      "  {\n",
      "    \"English\": \"But that “if” is important. Metaphors can be particularly helpful in explaining unfamiliar concepts: imagining the Einsteinian model of gravity (heavy objects distort space-time) as something like a bowling ball on a trampoline, for example. But metaphors can also be misleading: picturing the atom as a solar system helps young students of chemistry, but the more advanced learn that electrons move in clouds of probability, not in neat orbits as planets do.\",\n",
      "    \"Chinese\": \"但是这个“如果”很重要。隐喻在解释陌生概念时可能特别有帮助：例如，将爱因斯坦的引力模型（重物扭曲时空）想象成在蹦床上的保龄球。但是隐喻也可能具有误导性：将原子描绘成太阳系有助于化学初学者，但更高级的学生会了解到电子在概率云中运动，而不是像行星那样的整洁轨道。\"\n",
      "  },\n",
      "  {\n",
      "    \"English\": \"What may be an even more misleading metaphor—for artificial intelligence (ai)—seems to be taking hold. ai systems can now perform staggeringly impressive tasks, and their ability to reproduce what seems like the most human function of all, namely language, has ever more observers writing about them. When they do, they are tempted by an obvious (but obviously wrong) metaphor, which portrays ai programmes as conscious and even intentional agents. After all, the only other creatures which can use language are other conscious agents—that is, humans.\",\n",
      "    \"Chinese\": \"一个更具误导性的隐喻——人工智能（ai）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 20:57:11,818 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"4dcbabb3-c2f8-41a2-bf04-eeaa2e2fb06b\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"English\": \"“Hallucinations” might be thought of as a forgiving euphemism. Your friendly local AI is just having a bit of a bad trip; leave him to sleep it off and he’ll be back to himself in no time. For the “lies” crowd, though, the humanizing metaphor is even more profound: the AI is not only thinking, but has desires and intentions. A lie, remember, is not any old false statement. It is one made with the goal of deceiving others. ChatGPT has no such goals at all.\",\n",
      "    \"Chinese\": \"“幻觉”可以被视为一种宽容的委婉说法。您友好的本地人工智能只是有点糟糕的经历；让他休息一下，很快他就会恢复正常。然而，对于“谎言”群体来说，这种人性化的隐喻更加深刻：人工智能不仅在思考，而且有欲望和意图。请记住，谎言不是任何一个老旧的虚假陈述。它是为了欺骗他人而做出的陈述。ChatGPT根本没有这样的目标。\"\n",
      "  },\n",
      "  {\n",
      "    \"English\": \"Humans’ tendency to anthropomorphize things they don’t understand is ancient, and may confer an evolutionary advantage. If, on spying a rustling in the bushes, you infer an agent (whether predator or spirit), no harm is done if you are wrong. If you assume there is nothing in the undergrowth and a leopard jumps out, you are in trouble. The all-too-human desire to smack or yell at a malfunctioning device comes from this ingrained instinct to see intentionality everywhere.\",\n",
      "    \"Chinese\": \"人类倾向于将他们不理解的事物拟人化的倾向是古老的，可能会带来进化上的优势。如果在灌木丛中发现有一阵沙沙声，你会推测出一个存在（无论是捕食者还是灵魂），如果你的推测是错误的，也不会造成任何伤害。如果你假设灌木丛中没有什么东西，而一只豹子跳出来，你就会陷入麻烦。对于损坏的设备进行拍打或大声叫喊的过度人性化欲望来源于这种根深蒂固的在任何地方都看到意图的本能。\"\n",
      "  },\n",
      "  {\n",
      "    \"English\": \"It is an instinct, however, that should be overridden when writing about AI. These systems, including those that seem to converse, merely take input and produce output. At their most basic level, they do nothing more than turn strings like 0010010101001010 into 1011100100100001 based on a set of instructions. Other parts of the software turn those 0s and 1s into words, giving a frightening—but false—sense that there is a ghost in the machine.\",\n",
      "    \"Chinese\": \"然而，在谈论人工智能时，\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 20:57:50,729 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"8786b628-ee70-428d-a07b-b0afa6139355\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"English\": \"But AI is too important for loose language. If entirely avoiding human-like metaphors is all but impossible, writers should offset them, early, with some suitably bloodless phrasing. “An LLM is designed to produce text that reflects patterns found in its vast training data,” or some such explanation, will help readers take any later imagery with due skepticism. Humans have evolved to spot ghosts in machines. Writers should avoid ushering them into that trap. Better to lead them out of it.■\",\n",
      "    \"Chinese\": \"但是对于AI来说，使用随意的语言是不可取的。如果完全避免人类化的隐喻几乎是不可能的，作者应该提前用一些适当冷淡的措辞来抵消它们。“一个LLM的设计目的是产生反映其庞大训练数据中的模式的文本”，或者类似的解释，将帮助读者对任何后来的意象保持适度的怀疑。人类进化出了察觉机器中的幽灵的能力。作者应该避免将读者引入这个陷阱。最好引导他们走出来。■\"\n",
      "  },\n",
      "  {\n",
      "    \"English\": \"Read more from Johnson, our columnist on language:\\nGestures are a subtle and vital form of communication (Jun 8th)\\nAs it spreads across the world, who owns English? (May 25th)\\nThe hazards of pronouncing foreign names on air (May 11th)\",\n",
      "    \"Chinese\": \"更多关于我们的语言专栏作家约翰逊的文章：\\n手势是一种微妙而重要的交流形式（6月8日）\\n随着英语在全球的传播，谁拥有它？（5月25日）\\n在空中发音外国名字的危险（5月11日）\"\n",
      "  },\n",
      "  {\n",
      "    \"English\": \"“Writing With Style”, a new version of The Economist‘s style guide by Lane Greene, our Johnson columnist, is out now.\",\n",
      "    \"Chinese\": \"《以风格写作》是由我们的约翰逊专栏作家Lane Greene编写的《经济学人》风格指南的新版本，现已发布。\"\n",
      "  },\n",
      "  {\n",
      "    \"English\": \"For more on the latest books, films, TV shows, albums, and controversies, sign up for Plot Twist, our weekly subscriber-only newsletter.\",\n",
      "    \"Chinese\": \"要了解更多关于最新的书籍、电影、电视节目、专辑和争议的信息，请订阅我们的每周订阅者专属通讯《情节转折》。\"\n",
      "  },\n",
      "  {\n",
      "    \"English\": \"This article appeared in the Culture section of the print edition under the headline \\\"The ghost in the AI machine\\\".\",\n",
      "    \"Chinese\": \"本文刊载在印刷版的文化版面，标题为“AI机器中的幽灵”。\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for context in texts:\n",
    "    text = context.page_content\n",
    "    r = translate_chain(text)\n",
    "    print(r[\"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Retrieval QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Volumes/Usir/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from chromadb.config import Settings\n",
    "import chromadb\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"GanymedeNil/text2vec-large-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectordb = Chroma(collection_name=\"NationalLawsAndRegulationsDatabase\",\n",
    "                  embedding_function=embeddings,\n",
    "                  client=chromadb.Client(Settings(\n",
    "                      chroma_db_impl=\"duckdb+parquet\",\n",
    "                      persist_directory=\"/Volumes/Usir/DB/chromadb\"\n",
    "                  )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 21:13:52,782 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"9d06dd68-73ba-472a-a0ce-78f371a39ae1\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 21:14:00,770 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"e39b72e8-bba5-4a3d-8b76-aea1a9d3c0ba\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 21:14:41,523 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"0bf19a6b-b483-4abf-82fd-7c3df4d30e23\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "2023-06-28 21:14:50,638 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"907670b0-7f3b-40d8-9a3b-2129ec2ff826\", \"author\": {\"role\": \"assistant\", \"name\": n...\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2669 > 1024). Running this sequence through the model will result in indexing errors\n",
      "2023-06-28 21:15:30,473 - use_requests.py - 252 - INFO - success in getting  data\n",
      "{\"message\": {\"id\": \"aaefed75-e6ef-4d7a-95c9-a25e0cbe7bd5\", \"author\": {\"role\": \"assistant\", \"name\": n...\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'intermediate_steps': ['根据提供的法律部分原文，以下机构对噪声污染负有监管责任：\\n\\n- 国务院生态环境主管部门（负责制定噪声监测和评价规范，组织声环境质量监测，发布全国声环境质量状况信息）\\n- 地方人民政府生态环境主管部门（按照规定设置本行政区域声环境质量监测站，组织本行政区域声环境质量监测，向社会公布声环境质量状况信息）\\n- 其他负有噪声污染防治监督管理职责的部门（参与约谈地区政府及其有关部门的主要负责人，进行现场检查，处理噪声污染相关举报等）\\n\\n需要注意的是，具体的监管责任可能根据地区和具体情况有所不同。因此，建议在特定情况下咨询当地相关法律法规以获取准确和具体的信息。',\n  '生态环境主管部门、其他负有噪声污染防治监督管理职责的部门、县级以上人民政府市场监督管理部门、海关、县级以上地方人民政府住房和城乡建设主管部门。',\n  '第七十条 对噪声敏感建筑物集中区域的社会生活噪声扰民行为，基层群众性自治组织、业主委员会、物业服务人应当及时劝阻、调解；劝阻、调解无效的，可以向负有社会生活噪声污染防治监督管理职责的部门或者地方人民政府指定的部门报告或者投诉，接到报告或者投诉的部门应当依法处理。\\n第七十一条 违反本法规定，拒绝、阻挠监督检查，或者在接受监督检查时弄虚作假的，由生态环境主管部门或者其他负有噪声污染防治监督管理职责的部门责令改正，处二万元以上二十万元以下的罚款。\\n第七十二条 违反本法规定，生产、进口、销售超过噪声限值的产品的，由县级以上人民政府市场监督管理部门、海关按照职责责令改正，没收违法所得，并处货值金额一倍以上三倍以下的罚款；情节严重的，报经有批准权的人民政府批准，责令停业、关闭。\\n第七十三条 违反本法规定，建设单位建设噪声敏感建筑物不符合民用建筑隔声设计相关标准要求的，由县级以上地方人民政府住房和城乡建设主管部门责令改正，处建设工程合同价款百分之二以上百分之四以下的罚款。\\n违反本法规定，建设单位在噪声敏感建筑物禁止建设区域新建与航空无关的噪声敏感建筑物的，由地方人民政府指定的部门责令停止违法行为，处建设工程合同价款百分之二以上百分之十以下的罚款，并报经有批准权的人民政府批准，责令拆除。\\n第七十四条 违反本法规定，在噪声敏感建筑物集中区域新建排放噪声的工业企业的，由生态环境主管部门责令停止违法行为，处十万元以上五十万元以下的罚款，并报经有批准权的人民政府批准，责令关闭。\\n违反本法规定，在噪声敏感建筑物集中区域改建、扩建工业企业，未采取有效措',\n  '根据提供的原文，无法直接找到与噪声污染相关的内容。这份法律部分原文主要关注产品质量的监督和管理，没有提及噪声污染或相关的监管责任。如果有关噪声污染的法律规定，它们可能出现在其他法律文件中。'],\n 'output_text': '根据提供的法律部分原文，以下机构对噪声污染负有监管责任：\\n\\n- 国务院生态环境主管部门（负责制定噪声监测和评价规范，组织声环境质量监测，发布全国声环境质量状况信息）\\n- 地方人民政府生态环境主管部门（按照规定设置本行政区域声环境质量监测站，组织本行政区域声环境质量监测，向社会公布声环境质量状况信息）\\n- 其他负有噪声污染防治监督管理职责的部门（参与约谈地区政府及其有关部门的主要负责人，进行现场检查，处理噪声污染相关举报等）\\n\\n需要注意的是，具体的监管责任可能根据地区和具体情况有所不同。因此，建议在特定情况下咨询当地相关法律法规以获取准确和具体的信息。\\n\\n生态环境主管部门、其他负有噪声污染防治监督管理职责的部门、县级以上人民政府市场监督管理部门、海关、县级以上地方人民政府住房和城乡建设主管部门。\\n\\n第七十条 对噪声敏感建筑物集中区域的社会生活噪声扰民行为，基层群众性自治组织、业主委员会、物业服务人应当及时劝阻、调解；劝阻、调解无效的，可以向负有社会生活噪声污染防治监督管理职责的部门或者地方人民政府指定的部门报告或者投诉，接到报告或者投诉的部门应当依法处理。\\n\\n第七十一条 违反本法规定，拒绝、阻挠监督检查，或者在接受监督检查时弄虚作假的，由生态环境主管部门或者其他负有噪声污染防治监督管理职责的部门责令改正，处二万元以上二十万元以下的罚款。\\n\\n第七十二条 违反本法规定，生产、进口、销售超过噪声限值的产品的，由县级以上人民政府市场监督管理部门、海关按照职责责令改正，没收违法所得，并处货值金额一倍以上三倍以下的罚款；情节严重的，报经有批准权的人民'}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"法律规定哪些机构对噪声污染负有监管责任？\"\n",
    "retriever = vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"filter\":{\"status\": \"有效\"}})\n",
    "texts = retriever.get_relevant_documents(question)\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "question_prompt_template = \"\"\"使用以下法律部分原文，查看是否有任何文本与回答问题相关。仅返回任何相关的原样原格式文本。你不要自己添加内容。\n",
    "\n",
    "[[[{context}]]]\n",
    "\n",
    "问题: {question}\n",
    "原样文本：\"\"\"\n",
    "QUESTION_PROMPT = PromptTemplate(\n",
    "    template=question_prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "combine_prompt_template = \"\"\"扮演一个律师，利用下面的法律部分原文回答用户的问题，\n",
    "如果你不知道答案就回复：无法解答。不要编造内容回复。\n",
    "\n",
    "问题: {question}\n",
    "\n",
    "[[[{summaries}]]]\n",
    "\n",
    "答案:\"\"\"\n",
    "COMBINE_PROMPT = PromptTemplate(\n",
    "    template=combine_prompt_template, input_variables=[\"summaries\", \"question\"]\n",
    ")\n",
    "\n",
    "load_qa_chain_map_reduce = load_qa_chain(chat_agent_LLM, chain_type=\"map_reduce\", return_map_steps=True, question_prompt=QUESTION_PROMPT, combine_prompt=COMBINE_PROMPT)\n",
    "load_qa_chain_map_reduce({\"input_documents\": texts, \"question\": question}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 清空所有对话"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chat_agent.del_conversation_local()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 关闭对话"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 21:55:08,126 - auth_handler.py - 70 - INFO - success in saving chatgpt cookies.json\n",
      "2023-06-28 21:55:09,005 - conversation.py - 87 - WARNING - get conversation history failed [Status Code] 403\n",
      "2023-06-28 21:55:09,006 - use_requests.py - 174 - ERROR - <class 'exceptions.Requests403Error'> e\n"
     ]
    }
   ],
   "source": [
    "chat_agent_LLM.chat_agent.quit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}